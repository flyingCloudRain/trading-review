#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¿å—æ•°æ®å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
"""
import logging
from datetime import datetime, time, date, timedelta
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from database.db import SessionLocal
from services.sector_history_service import SectorHistoryService
from services.zt_pool_history_service import ZtPoolHistoryService
from services.zbgc_pool_history_service import ZbgcPoolHistoryService
from services.dtgc_pool_history_service import DtgcPoolHistoryService
from services.index_history_service import IndexHistoryService
from services.scheduler_execution_service import SchedulerExecutionService
from utils.excel_export import append_sectors_to_excel
from utils.time_utils import UTC8, get_utc8_date, get_utc8_now
import akshare as ak
import traceback

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SectorScheduler:
    """æ¿å—æ•°æ®å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨"""
    
    def __init__(self):
        # ä½¿ç”¨UTC+8æ—¶åŒºï¼ˆåŒ—äº¬æ—¶é—´ï¼‰
        self.scheduler = BackgroundScheduler(timezone=UTC8)
        # ä½¿ç”¨è¿›ç¨‹é”ï¼Œé˜²æ­¢å¤šä¸ªå®ä¾‹åŒæ—¶è¿è¡Œ
        self.scheduler.add_jobstore('memory', alias='default')
        self._setup_jobs()
    
    def _setup_jobs(self):
        """è®¾ç½®å®šæ—¶ä»»åŠ¡"""
        # æ¯æ—¥15:10æ‰§è¡Œï¼ˆåŒ—äº¬æ—¶é—´ï¼‰- ä¿å­˜æ‰€æœ‰æ•°æ®ï¼ˆæ”¶ç›˜åæœ€ç»ˆæ•°æ®ï¼‰
        self.scheduler.add_job(
            func=self.save_daily_data,
            trigger=CronTrigger(hour=15, minute=10, timezone=UTC8),
            id='save_daily_data',
            name='æ¯æ—¥15:10ä¿å­˜æ¿å—å’Œè‚¡ç¥¨æ± æ•°æ®',
            replace_existing=True
        )
        
        # æ¯æ—¥15:10æ‰§è¡Œè·å–å³æ—¶èµ„é‡‘æµæ•°æ®ï¼ˆæ¦‚å¿µæ¿å—ï¼‰
        self.scheduler.add_job(
            func=self.save_realtime_fund_flow,
            trigger=CronTrigger(hour=15, minute=10, timezone=UTC8),
            id='save_realtime_fund_flow_1510',
            name='æ¯æ—¥15:10è·å–å³æ—¶èµ„é‡‘æµæ•°æ®',
            replace_existing=True
        )
        
        logger.info("å®šæ—¶ä»»åŠ¡å·²è®¾ç½®ï¼š")
        logger.info("  - æ¯æ—¥15:10ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰æ‰§è¡Œæ•°æ®ä¿å­˜ï¼ˆæ¿å—ã€æ¶¨åœã€ç‚¸æ¿ã€è·Œåœã€æŒ‡æ•°ï¼‰")
        logger.info("  - æ¯æ—¥15:10ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰è·å–å³æ—¶èµ„é‡‘æµæ•°æ®ï¼ˆæ¦‚å¿µæ¿å—ï¼‰")
    
    def _is_trading_day(self, target_date: date) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¥"""
        try:
            # ä½¿ç”¨ akshare è·å–äº¤æ˜“æ—¥å†
            trade_dates = ak.tool_trade_date_hist_sina()
            if trade_dates is not None and not trade_dates.empty:
                # å°†ç›®æ ‡æ—¥æœŸè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ YYYYMMDD
                date_str = target_date.strftime('%Y%m%d')
                
                # äº¤æ˜“æ—¥å†è¿”å›çš„æ—¥æœŸæ ¼å¼å¯èƒ½æ˜¯ 'YYYY-MM-DD' å­—ç¬¦ä¸²
                # éœ€è¦å…ˆè½¬æ¢ä¸ºæ—¥æœŸå¯¹è±¡ï¼Œå†æ ¼å¼åŒ–ä¸º YYYYMMDD è¿›è¡Œæ¯”è¾ƒ
                import pandas as pd
                trade_dates['date_str'] = pd.to_datetime(trade_dates['trade_date']).dt.strftime('%Y%m%d')
                trade_date_list = trade_dates['date_str'].tolist()
                
                is_trading = date_str in trade_date_list
                logger.debug(f"æ£€æŸ¥æ—¥æœŸ {target_date} ({date_str}) æ˜¯å¦ä¸ºäº¤æ˜“æ—¥: {is_trading}")
                return is_trading
            else:
                logger.warning("æ— æ³•è·å–äº¤æ˜“æ—¥å†æ•°æ®ï¼Œé»˜è®¤è®¤ä¸ºæ˜¯äº¤æ˜“æ—¥")
                return True  # å¦‚æœæ— æ³•è·å–äº¤æ˜“æ—¥å†ï¼Œé»˜è®¤è®¤ä¸ºæ˜¯äº¤æ˜“æ—¥
        except Exception as e:
            logger.warning(f"æ— æ³•åˆ¤æ–­äº¤æ˜“æ—¥ï¼Œé»˜è®¤æ‰§è¡Œ: {str(e)}")
            return True  # å¦‚æœå‡ºé”™ï¼Œé»˜è®¤æ‰§è¡Œ
    
    def save_daily_data(self):
        """ä¿å­˜æ¯æ—¥æ•°æ®åˆ° Supabase æ•°æ®åº“ï¼ˆæ¿å—ã€æ¶¨åœã€ç‚¸æ¿ã€è·Œåœã€æŒ‡æ•°ï¼‰"""
        job_id = 'save_daily_data'
        job_name = 'æ¯æ—¥15:10ä¿å­˜æ¿å—å’Œè‚¡ç¥¨æ± æ•°æ®'
        execution_start_time = get_utc8_now()
        today = get_utc8_date()
        is_trading = self._is_trading_day(today)
        
        # åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®
        stats = {
            'industry_sectors_count': 0,
            'concept_sectors_count': 0,
            'zt_pool_count': 0,
            'zbgc_pool_count': 0,
            'dtgc_pool_count': 0,
            'index_count': 0,
        }
        
        error_message = None
        error_traceback = None
        status = 'success'
        
        try:
            logger.info("=" * 60)
            logger.info("å¼€å§‹æ‰§è¡Œæ¯æ—¥æ•°æ®ä¿å­˜ä»»åŠ¡ï¼ˆä¿å­˜åˆ° Supabase æ•°æ®åº“ï¼‰...")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
            if not is_trading:
                logger.info(f"ä»Šæ—¥ ({today}) ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œè·³è¿‡æ•°æ®ä¿å­˜")
                status = 'skipped'
                # è®°å½•è·³è¿‡æ‰§è¡Œ
                db = SessionLocal()
                try:
                    SchedulerExecutionService.create_execution(
                        db=db,
                        job_id=job_id,
                        job_name=job_name,
                        execution_date=today,
                        execution_time=execution_start_time,
                        status=status,
                        duration_seconds=(get_utc8_now() - execution_start_time).total_seconds(),
                        is_trading_day=is_trading,
                        notes=f"éäº¤æ˜“æ—¥ï¼Œè·³è¿‡æ‰§è¡Œ"
                    )
                finally:
                    db.close()
                return
            
            # éªŒè¯æ•°æ®åº“è¿æ¥ï¼ˆç¡®ä¿ä½¿ç”¨ Supabaseï¼‰
            try:
                from database.db_supabase import engine
                from sqlalchemy import text
                # æµ‹è¯•æ•°æ®åº“è¿æ¥
                with engine.connect() as conn:
                    conn.execute(text("SELECT 1"))
                logger.info("âœ… Supabase æ•°æ®åº“è¿æ¥æ­£å¸¸")
            except Exception as e:
                logger.error(f"âŒ Supabase æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
                raise
            
            # è·å–æ•°æ®åº“ä¼šè¯ï¼ˆä½¿ç”¨ Supabaseï¼‰
            db = SessionLocal()
            try:
                logger.info(f"ğŸ“Š å¼€å§‹ä¿å­˜ {today} çš„æ•°æ®åˆ° Supabase æ•°æ®åº“...")
                
                # 1. ä¿å­˜è¡Œä¸šæ¿å—æ•°æ®åˆ° Supabaseï¼ˆæ˜ç¡®ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸï¼‰
                try:
                    saved_count = SectorHistoryService.save_today_sectors(db, sector_type='industry', target_date=today)
                    stats['industry_sectors_count'] = saved_count
                    logger.info(f"âœ… æˆåŠŸä¿å­˜ {saved_count} æ¡è¡Œä¸šæ¿å—æ•°æ®åˆ° Supabase æ•°æ®åº“ ({today})")
                    
                    # è¿½åŠ åˆ°Excelæ–‡ä»¶
                    excel_file = append_sectors_to_excel()
                    logger.info(f"âœ… æˆåŠŸè¿½åŠ è¡Œä¸šæ¿å—æ•°æ®åˆ°Excelæ–‡ä»¶: {excel_file}")
                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜è¡Œä¸šæ¿å—æ•°æ®åˆ° Supabase å¤±è´¥: {str(e)}", exc_info=True)
                    if status == 'success':
                        status = 'failed'
                        error_message = f"ä¿å­˜è¡Œä¸šæ¿å—æ•°æ®å¤±è´¥: {str(e)}"
                
                # 1.1 ä¿å­˜æ¦‚å¿µæ¿å—æ•°æ®åˆ° Supabaseï¼ˆæ˜ç¡®ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸï¼‰
                try:
                    concept_count = SectorHistoryService.save_today_sectors(db, sector_type='concept', target_date=today)
                    stats['concept_sectors_count'] = concept_count
                    logger.info(f"âœ… æˆåŠŸä¿å­˜ {concept_count} æ¡æ¦‚å¿µæ¿å—æ•°æ®åˆ° Supabase æ•°æ®åº“ ({today})")
                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜æ¦‚å¿µæ¿å—æ•°æ®åˆ° Supabase å¤±è´¥: {str(e)}", exc_info=True)
                    if status == 'success':
                        status = 'failed'
                        error_message = f"ä¿å­˜æ¦‚å¿µæ¿å—æ•°æ®å¤±è´¥: {str(e)}"
                
                # 2. ä¿å­˜æ¶¨åœè‚¡ç¥¨æ± æ•°æ®åˆ° Supabaseï¼ˆæ˜ç¡®ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸï¼‰
                try:
                    zt_count = ZtPoolHistoryService.save_today_zt_pool(db, target_date=today)
                    stats['zt_pool_count'] = zt_count
                    logger.info(f"âœ… æˆåŠŸä¿å­˜ {zt_count} æ¡æ¶¨åœè‚¡ç¥¨æ•°æ®åˆ° Supabase æ•°æ®åº“ ({today})")
                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜æ¶¨åœè‚¡ç¥¨æ•°æ®åˆ° Supabase å¤±è´¥: {str(e)}", exc_info=True)
                    if status == 'success':
                        status = 'failed'
                        error_message = f"ä¿å­˜æ¶¨åœè‚¡ç¥¨æ•°æ®å¤±è´¥: {str(e)}"
                
                # 3. ä¿å­˜ç‚¸æ¿è‚¡ç¥¨æ± æ•°æ®åˆ° Supabaseï¼ˆæ˜ç¡®ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸï¼‰
                try:
                    zbgc_count = ZbgcPoolHistoryService.save_today_zbgc_pool(db, target_date=today)
                    stats['zbgc_pool_count'] = zbgc_count
                    logger.info(f"âœ… æˆåŠŸä¿å­˜ {zbgc_count} æ¡ç‚¸æ¿è‚¡ç¥¨æ•°æ®åˆ° Supabase æ•°æ®åº“ ({today})")
                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜ç‚¸æ¿è‚¡ç¥¨æ•°æ®åˆ° Supabase å¤±è´¥: {str(e)}", exc_info=True)
                    if status == 'success':
                        status = 'failed'
                        error_message = f"ä¿å­˜ç‚¸æ¿è‚¡ç¥¨æ•°æ®å¤±è´¥: {str(e)}"
                
                # 4. ä¿å­˜è·Œåœè‚¡ç¥¨æ± æ•°æ®åˆ° Supabaseï¼ˆæ˜ç¡®ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸï¼‰
                try:
                    dtgc_count = DtgcPoolHistoryService.save_today_dtgc_pool(db, target_date=today)
                    stats['dtgc_pool_count'] = dtgc_count
                    logger.info(f"âœ… æˆåŠŸä¿å­˜ {dtgc_count} æ¡è·Œåœè‚¡ç¥¨æ•°æ®åˆ° Supabase æ•°æ®åº“ ({today})")
                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜è·Œåœè‚¡ç¥¨æ•°æ®åˆ° Supabase å¤±è´¥: {str(e)}", exc_info=True)
                    if status == 'success':
                        status = 'failed'
                        error_message = f"ä¿å­˜è·Œåœè‚¡ç¥¨æ•°æ®å¤±è´¥: {str(e)}"
                
                # 5. ä¿å­˜æŒ‡æ•°æ•°æ®åˆ° Supabaseï¼ˆæ˜ç¡®ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸï¼‰
                try:
                    index_count = IndexHistoryService.save_today_indices(db, target_date=today)
                    stats['index_count'] = index_count
                    logger.info(f"âœ… æˆåŠŸä¿å­˜ {index_count} æ¡æŒ‡æ•°æ•°æ®åˆ° Supabase æ•°æ®åº“ ({today})")
                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜æŒ‡æ•°æ•°æ®åˆ° Supabase å¤±è´¥: {str(e)}", exc_info=True)
                    if status == 'success':
                        status = 'failed'
                        error_message = f"ä¿å­˜æŒ‡æ•°æ•°æ®å¤±è´¥: {str(e)}"
                
                logger.info("=" * 60)
                logger.info(f"âœ… æ¯æ—¥æ•°æ®ä¿å­˜ä»»åŠ¡å®Œæˆï¼Œæ‰€æœ‰æ•°æ®å·²ä¿å­˜åˆ° Supabase æ•°æ®åº“ ({today})")
                logger.info("=" * 60)
                
            except Exception as e:
                logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {str(e)}", exc_info=True)
                status = 'failed'
                error_message = str(e)
                error_traceback = traceback.format_exc()
            finally:
                # è®°å½•æ‰§è¡Œæƒ…å†µ
                execution_end_time = get_utc8_now()
                duration = (execution_end_time - execution_start_time).total_seconds()
                
                try:
                    SchedulerExecutionService.create_execution(
                        db=db,
                        job_id=job_id,
                        job_name=job_name,
                        execution_date=today,
                        execution_time=execution_start_time,
                        status=status,
                        duration_seconds=duration,
                        industry_sectors_count=stats['industry_sectors_count'],
                        concept_sectors_count=stats['concept_sectors_count'],
                        zt_pool_count=stats['zt_pool_count'],
                        zbgc_pool_count=stats['zbgc_pool_count'],
                        dtgc_pool_count=stats['dtgc_pool_count'],
                        index_count=stats['index_count'],
                        error_message=error_message,
                        error_traceback=error_traceback,
                        is_trading_day=is_trading,
                        notes=f"æ€»è€—æ—¶: {duration:.2f}ç§’"
                    )
                    logger.info(f"âœ… æ‰§è¡Œè®°å½•å·²ä¿å­˜åˆ°æ•°æ®åº“")
                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜æ‰§è¡Œè®°å½•å¤±è´¥: {str(e)}", exc_info=True)
                finally:
                    db.close()
                
        except Exception as e:
            logger.error(f"å®šæ—¶ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
            # è®°å½•å¤±è´¥æ‰§è¡Œ
            execution_end_time = get_utc8_now()
            duration = (execution_end_time - execution_start_time).total_seconds()
            db = SessionLocal()
            try:
                SchedulerExecutionService.create_execution(
                    db=db,
                    job_id=job_id,
                    job_name=job_name,
                    execution_date=today,
                    execution_time=execution_start_time,
                    status='failed',
                    duration_seconds=duration,
                    error_message=str(e),
                    error_traceback=traceback.format_exc(),
                    is_trading_day=is_trading,
                    notes="ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸"
                )
            finally:
                db.close()
    
    def save_realtime_fund_flow(self):
        """ä¿å­˜å³æ—¶èµ„é‡‘æµæ•°æ®åˆ° Supabase æ•°æ®åº“ï¼ˆæ¦‚å¿µæ¿å—ï¼‰- æ¯æ—¥15:10æ‰§è¡Œ"""
        job_id = 'save_realtime_fund_flow_1510'
        job_name = 'æ¯æ—¥15:10è·å–å³æ—¶èµ„é‡‘æµæ•°æ®'
        execution_start_time = get_utc8_now()
        today = get_utc8_date()
        is_trading = self._is_trading_day(today)
        
        # åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®
        concept_count = 0
        error_message = None
        error_traceback = None
        status = 'success'
        
        try:
            logger.info("=" * 60)
            logger.info("å¼€å§‹æ‰§è¡Œå³æ—¶èµ„é‡‘æµæ•°æ®ä¿å­˜ä»»åŠ¡ï¼ˆä¿å­˜åˆ° Supabase æ•°æ®åº“ï¼‰...")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
            if not is_trading:
                logger.info(f"ä»Šæ—¥ ({today}) ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œè·³è¿‡å³æ—¶èµ„é‡‘æµæ•°æ®ä¿å­˜")
                status = 'skipped'
                # è®°å½•è·³è¿‡æ‰§è¡Œ
                db = SessionLocal()
                try:
                    SchedulerExecutionService.create_execution(
                        db=db,
                        job_id=job_id,
                        job_name=job_name,
                        execution_date=today,
                        execution_time=execution_start_time,
                        status=status,
                        duration_seconds=(get_utc8_now() - execution_start_time).total_seconds(),
                        is_trading_day=is_trading,
                        notes=f"éäº¤æ˜“æ—¥ï¼Œè·³è¿‡æ‰§è¡Œ"
                    )
                finally:
                    db.close()
                return
            
            # éªŒè¯æ•°æ®åº“è¿æ¥ï¼ˆç¡®ä¿ä½¿ç”¨ Supabaseï¼‰
            try:
                from database.db_supabase import engine
                from sqlalchemy import text
                # æµ‹è¯•æ•°æ®åº“è¿æ¥
                with engine.connect() as conn:
                    conn.execute(text("SELECT 1"))
                logger.info("âœ… Supabase æ•°æ®åº“è¿æ¥æ­£å¸¸")
            except Exception as e:
                logger.error(f"âŒ Supabase æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
                raise
            
            # è·å–æ•°æ®åº“ä¼šè¯ï¼ˆä½¿ç”¨ Supabaseï¼‰
            db = SessionLocal()
            try:
                logger.info(f"ğŸ“Š å¼€å§‹ä¿å­˜ {today} çš„æ¦‚å¿µæ¿å—å³æ—¶èµ„é‡‘æµæ•°æ®åˆ° Supabase æ•°æ®åº“...")
                
                # ä¿å­˜æ¦‚å¿µæ¿å—å³æ—¶èµ„é‡‘æµæ•°æ®åˆ° Supabaseï¼ˆæ˜ç¡®ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸï¼‰
                try:
                    concept_count = SectorHistoryService.save_today_sectors(db, sector_type='concept', target_date=today)
                    logger.info(f"âœ… æˆåŠŸä¿å­˜ {concept_count} æ¡æ¦‚å¿µæ¿å—å³æ—¶èµ„é‡‘æµæ•°æ®åˆ° Supabase æ•°æ®åº“ ({today})")
                except Exception as e:
                    logger.error(f"âŒ ä¿å­˜æ¦‚å¿µæ¿å—å³æ—¶èµ„é‡‘æµæ•°æ®åˆ° Supabase å¤±è´¥: {str(e)}", exc_info=True)
                
                logger.info("=" * 60)
                logger.info("âœ… å³æ—¶èµ„é‡‘æµæ•°æ®ä¿å­˜ä»»åŠ¡å®Œæˆï¼Œæ•°æ®å·²ä¿å­˜åˆ° Supabase æ•°æ®åº“")
                logger.info("=" * 60)
                
            except Exception as e:
                logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {str(e)}", exc_info=True)
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"å³æ—¶èµ„é‡‘æµå®šæ—¶ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)
    
    def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        self.scheduler.start()
        logger.info("æ¿å—æ•°æ®å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")
    
    def shutdown(self):
        """å…³é—­è°ƒåº¦å™¨"""
        self.scheduler.shutdown()
        logger.info("æ¿å—æ•°æ®å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å…³é—­")

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
_scheduler = None

def get_scheduler():
    """è·å–è°ƒåº¦å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _scheduler
    if _scheduler is None:
        _scheduler = SectorScheduler()
    return _scheduler

